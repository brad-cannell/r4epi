{
  "hash": "6f5d5d0ee4ff8f41f6d01f68722f425f",
  "result": {
    "engine": "knitr",
    "markdown": "# Importing Binary Files\n\n<!-- \nHidden comments placeholder\n---------------------------\n\nFile path for importing files interactively (testing):\n\"/Users/bradcannell/Dropbox/R4Epi Textbook/r4epi/data/file_name.ext\"\n\nFile path for importing files when building the book:\n\"file_name.ext\"\n\nTo preview:\nbookdown::preview_chapter(\"chapters/importing_binary_files/importing_binary_files.qmd\")\n\nCopy and paste:\nðŸ‘†**Here's what we did above:**\n-->\n\nIn the last chapter we learned that there are many different file types that one can use to store data. We also learned how to use the `readr` package to import several different variations of **plain text files** into R. \n\nIn this chapter, we will focus on data stored in **binary files**. Again, you can think of binary files as being more complex than plain text files and accessing the information in binary files requires the use of special software. Some examples of binary files that we have frequently seen used in epidemiology include Microsoft Excel spreadsheets, SAS data sets, and Stata data sets. Below, we will learn how to import all three file types into R.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](files.png){width=6in}\n:::\n:::\n\n\n\n\n\n\n## Packages for importing data\n\nTechnically, base R does not contain any functions that can be used to import the binary file types discussed above. However, the `foreign` package contains functions that may be used to import SAS data sets and Stata data sets, and is installed by default when you install R on your computer. Having said that, we aren't going to use the `foreign` package in this chapter. Instead, we're going to use the following packages to import data in the examples below. If you haven't done so already, we suggest that you go ahead and install these packages now. \n\n* [readxl](https://readxl.tidyverse.org/). We will use the `readxl` package to import Microsoft Excel files.\n\n* [haven](https://haven.tidyverse.org/). We will use the `haven` package to import SAS and Stata data sets.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(haven)\n```\n:::\n\n\n\n\n\n\n## Importing Microsoft Excel spreadsheets\n\nWe probably sent data in Microsoft Excel files more than any other file format. Fortunately, the `readxl` package makes it really easy to import Excel spreadsheets into R. And, because that package is maintained by the same people who create the `readr` package that you have already seen, we think it's likely that the `readxl` package will feel somewhat familiar right from the start.\n\nWe would be surprised if any of you had never seen an Excel spreadsheet before -- they are pretty ubiquitous in the modern world -- but we'll go ahead and show a screenshot of our height and weight data in Excel for the sake of completeness.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](excel.png){width=6in}\n:::\n:::\n\n\n\n\n\n\nAll we have to do to import this spreadsheet into R as a data frame is passing the path to the excel file to the `path` argument of the `read_excel()` function. \n\n[You may click here to download this file to your computer.](https://github.com/brad-cannell/r4epi/blob/master/data/excel.xlsx)\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexcel <- read_excel(\"excel.xlsx\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexcel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 4\n  ID    sex    ht_in wgt_lbs\n  <chr> <chr>  <dbl>   <dbl>\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\nðŸ‘†**Here's what we did above:**\n\n* We used `readxl`'s `read_excel()` function to import a Microsoft Excel spreadsheet. That spreadsheet was imported as a data frame and we assigned that data frame to the R object called `excel`.\n\n::: callout-warning\nMake sure to always include the file extension in your file paths. For example, using \"/excel\" instead of \"/excel.xlsx\" above (i.e., no .xlsx) would have resulted in an error telling you that the filed does not exist.\n:::\n\nFortunately for us, just passing the Excel file to the `read_excel()` function like this will usually \"just work.\" But, let's go ahead and simulate another situation that is slightly more complex. Once again, we've received data from a team that is using Microsoft Excel to capture some study data. \n\n\n\n\n\n\n::: {.cell lable='excel_complex'}\n::: {.cell-output-display}\n![](excel_complex.png){width=6in}\n:::\n:::\n\n\n\n\n\n\nAs you can see, this data looks very similar to the csv file we previously imported. However, it looks like the study team has done a little more formatting this time. Additionally, they've added a couple of columns we haven't seen before -- date of birth and annual household income. \n\nAs a final little wrinkle, the data for this study is actually the second sheet in this Excel file (also called a workbook). The study team used the first sheet in the workbook as a data dictionary that looks like this:\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](data_dictionary.png){width=6in}\n:::\n:::\n\n\n\n\n\n\nOnce again, we will have to deal with some of the formatting that was done in Excel before we can analyze our data in R.\n\n[You may click here to download this file to your computer.](https://github.com/brad-cannell/r4epi/blob/master/data/excel_complex.xlsx)\n\nWe'll start by taking a look at the result we get when we try to pass this file to the `read_excel()` function without changing any of `read_excel()`'s default values.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexcel <- read_excel(\"excel_complex.xlsx\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\n* `` -> `...2`\n* `` -> `...3`\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexcel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 x 3\n  `Height and Weight Study\\r\\nData Dictionary` ...2                        ...3 \n  <chr>                                        <chr>                       <chr>\n1 <NA>                                         <NA>                        <NA> \n2 Variable                                     Definition                  Type \n3 Study ID                                     Randomly assigned particip~ Cont~\n4 Assigned Sex at Birth                        Sex the participant was as~ Dich~\n5 Height (inches)                              Participant's height in in~ Cont~\n6 Weight (lbs)                                 Participant's weight in po~ Cont~\n7 Date of Birth                                Participant's date of birth Date \n8 Annual Household Income                      Participant's annual house~ Cont~\n```\n\n\n:::\n:::\n\n\n\n\n\n\nAnd, as we're sure you saw coming, this isn't the result we wanted. However, we can get the result we wanted by making a few tweaks to the default values of the `sheet`, `col_names`, `col_types`, `skip`, and `na` arguments of the `read_excel()` function.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexcel <- read_excel(\n  path = \"excel_complex.xlsx\",\n  sheet = \"Study Phase 1\",\n  col_names = c(\"id\", \"sex\", \"ht_in\", \"wgt_lbs\", \"dob\", \"income\"),\n  col_types = c(\n    \"text\",\n    \"text\",\n    \"numeric\",\n    \"numeric\",\n    \"date\",\n    \"numeric\",\n    \"skip\"\n  ),\n  skip = 3,\n  na = c(\"\", \"NA\", \"Missing\")\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexcel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 6\n  id    sex    ht_in wgt_lbs dob                 income\n  <chr> <chr>  <dbl>   <dbl> <dttm>               <dbl>\n1 001   Male      71     190 1981-05-20 00:00:00  46000\n2 002   Male      NA     176 1990-08-16 00:00:00  67000\n3 003   Female    64     130 1980-02-21 00:00:00  49000\n4 004   Female    65      NA 1983-04-12 00:00:00  89000\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\nAs we said, the `readr` package and `readxl` package were developed by the same people. So, the code above looks similar to the code we used to import the csv file in the previous chapter. Therefore, we're not going to walk through this code step-by-step. Rather, we're just going to highlight some of the slight differences.\n\n* You can type `?read_excel` into your R console to view the help documentation for this function and follow along with the explanation below.\n\n* The first argument to the `read_excel()` function is the `path` argument. It serves the same purpose as the `file` argument to `read_csv()` -- it just has a different name.\n\n* The `sheet` argument to the `read_excel()` function tells R which sheet of the Excel workbook contains the data you want to import. In this case, the study team named that sheet \"Study Phase 1\". We could have also passed the value `2` to the `sheet` argument because \"Study Phase 1\" is the second sheet in the workbook. However, we suggest using the sheet name. That way, if the study team sends you a new Excel file next week with different ordering, you are less likely to accidentally import the wrong data.\n\n* The value we pass to the `col_types` argument is now a vector of character strings instead of a list of functions nested in the `col()` function. \n\n  - The values that the col_types function will accept are `\"skip\"` for telling R to ignore a column in the spreadsheet, `\"guess\"` for telling R to guess the variable type, `\"logical\"` for logical (TRUE/FALSE) variables, \"`numeric`\" for numeric variables, `\"date\"` for date variables, `\"text\"` for character variables, and `\"list\"` for everything else. \n  \n  - Notice that we told R to import income as a numeric variable. This caused the commas and dollar signs to be dropped. We did this because keeping the commas and dollar signs would have required us to make income a character variable (numeric variables can only include numbers). If we had imported income as a character variable, we would have lost the ability to perform mathematical operations on it. Remember, it makes no sense to \"add\" two words together. Later, we will show you how to add dollar signs and commas back to the numeric values if you want to display them in your final results.\n  \n* We used the `col_names`, `skip`, and `na` arguments in exactly the same way we used them in the read_csv function.\n\nYou should be able to import most of the data stored in Excel spreadsheets with just the few options that we discussed above. However, there may be times were importing spreadsheets is even more complicated. If you find yourself in that position, we suggest that you first check out [the readxl website here](https://readxl.tidyverse.org/index.html).\n\n## Importing data from other statistical analysis software\n\nMany applications designed for statistical analysis allow you to save data in a binary format. One reason for this is that binary data formats allow you to save **metadata** alongside your data values. Metadata is data _about_ the data. Using our running example, the data is about the heights, weights, and other characteristics of our study participants. **Metadata** about this data might include information like when this data set was created, or value labels that make the data easier to read (e.g., the dollar signs in the income variable).\n\nIn our experience, you are slightly more likely to have problems importing binary files saved from other statistical analysis applications than plain text files. Perhaps because they are more complex, the data just seems to become corrupt and do other weird things more often than is the case with plain text files. However, in our experience, it is also the case that when we are able to import binary files created in other statistical analysis applications, doing so requires less adjusting of default values. In fact, we will usually only need to pass the file path to the correct `read_` function.\n\nBelow, we will see some examples of importing binary files saved in two popular statistical analysis applications -- SAS and Stata. We will use the `haven` package to import both.\n\n## Importing SAS data sets\n\nSAS actually allows users to save data in more than one type of binary format. Data can be saved as SAS data sets or as SAS Transport files. SAS data set file names end with the .sas7bdat file extension. SAS Transport file file names end with the .xpt file extension. \n\nIn order to import a SAS data set, we typically only need to pass the correct file path to `haven`'s `read_sas()` function. \n\n[You may click here to download this file to your computer.](https://github.com/brad-cannell/r4epi/blob/master/data/height_and_weight.sas7bdat)\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsas <- read_sas(\"height_and_weight.sas7bdat\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsas\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 4\n  ID    sex    ht_in wgt_lbs\n  <chr> <chr>  <dbl>   <dbl>\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n```\n\n\n:::\n:::\n\n\n\n\n\n\nðŸ‘†**Here's what we did above:**\n\n* We used `haven`'s `read_sas()` function to import a SAS data set. That data was imported as a data frame and we assigned that data frame to the R object called `sas`.\n\nIn addition to SAS data sets, data that has been altered in SAS can also be saved as a SAS transport file. Some of the national, population-based public health surveys (e.g., BRFSS and NHANES) make their data publicly available in this format.\n\nYou can download the [2018 BRFSS data as a SAS Transport file here](https://www.cdc.gov/brfss/annual_data/annual_2018.html). About halfway down the webpage, there is a link that says, \"2018 BRFSS Data (SAS Transport Format)\". \n\n\n\n\n\n\n::: {.cell lable='download_brfss'}\n::: {.cell-output-display}\n![](download_brfss.png){width=6in}\n:::\n:::\n\n\n\n\n\n\nClicking that link should download the data to your computer. Notice that the SAS Transport file is actually stored _inside_ a zip file. You can unzip the file first if you would like, but you don't even have to do that. Amazingly, you can pass the path to the zipped .xpt file directly to the `read_xpt()` function like so:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrfss_2018 <- read_xpt(\"LLCP2018XPT.zip\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(brfss_2018)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 275\n  `_STATE` FMONTH IDATE    IMONTH IDAY  IYEAR DISPCODE SEQNO     `_PSU` CTELENM1\n     <dbl>  <dbl> <chr>    <chr>  <chr> <chr>    <dbl> <chr>      <dbl>    <dbl>\n1        1      1 01052018 01     05    2018      1100 20180000~ 2.02e9        1\n2        1      1 01122018 01     12    2018      1100 20180000~ 2.02e9        1\n3        1      1 01082018 01     08    2018      1100 20180000~ 2.02e9        1\n4        1      1 01032018 01     03    2018      1100 20180000~ 2.02e9        1\n5        1      1 01122018 01     12    2018      1100 20180000~ 2.02e9        1\n6        1      1 01112018 01     11    2018      1100 20180000~ 2.02e9        1\n# i 265 more variables: PVTRESD1 <dbl>, COLGHOUS <dbl>, STATERE1 <dbl>,\n#   CELLFON4 <dbl>, LADULT <dbl>, NUMADULT <dbl>, NUMMEN <dbl>, NUMWOMEN <dbl>,\n#   SAFETIME <dbl>, CTELNUM1 <dbl>, CELLFON5 <dbl>, CADULT <dbl>,\n#   PVTRESD3 <dbl>, CCLGHOUS <dbl>, CSTATE1 <dbl>, LANDLINE <dbl>,\n#   HHADULT <dbl>, GENHLTH <dbl>, PHYSHLTH <dbl>, MENTHLTH <dbl>,\n#   POORHLTH <dbl>, HLTHPLN1 <dbl>, PERSDOC2 <dbl>, MEDCOST <dbl>,\n#   CHECKUP1 <dbl>, EXERANY2 <dbl>, SLEPTIM1 <dbl>, CVDINFR4 <dbl>, ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\nðŸ‘†**Here's what we did above:**\n\n* We used `haven`'s `read_xpt()` function to import a zipped SAS Transport File. That data was imported as a data frame and we assigned that data frame to the R object called `brfss_2018`.\n\n* Because this is a large data frame (437,436 observations and 275 variables), we used the `head()` function to print only the first 6 rows of the data to the screen. \n\nBut, this demonstration actually gets even cooler. Instead of downloading the SAS Transport file to our computer before importing it, we can actually sometimes import files, including SAS Transport files, directly from the internet.\n\nFor example, you can download the [2017-2018 NHANES demographic data as a SAS Transport file here](https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Demographics&CycleBeginYear=2017)\n\n\n\n\n\n\n::: {.cell lable='nhanes_link'}\n::: {.cell-output-display}\n![](nhanes_link.png){width=6in}\n:::\n:::\n\n\n\n\n\n\nIf you right-click on the link that says, \"DEMO_J Data [XPT - 3.3 MB]\", you will see an option to copy the link address. \n\n\n\n\n\n\n::: {.cell lable='copy_link_address'}\n::: {.cell-output-display}\n![](copy_link_address.png){width=6in}\n:::\n:::\n\n\n\n\n\n\nClick \"Copy Link Address\" and then navigate back to RStudio. Now, all you have to do is paste that link address where you would normally type a file path into the `read_xpt()` function. When you run the code chunk, the `read_xpt()` function will import the NHANES data directly from the internet (assuming you are connected to the internet). ðŸ˜²\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnhanes_demo <- read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DEMO_J.xpt\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(nhanes_demo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 46\n   SEQN SDDSRVYR RIDSTATR RIAGENDR RIDAGEYR RIDAGEMN RIDRETH1 RIDRETH3 RIDEXMON\n  <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n1 93703       10        2        2        2       NA        5        6        2\n2 93704       10        2        1        2       NA        3        3        1\n3 93705       10        2        2       66       NA        4        4        2\n4 93706       10        2        1       18       NA        5        6        2\n5 93707       10        2        1       13       NA        5        7        2\n6 93708       10        2        2       66       NA        5        6        2\n# i 37 more variables: RIDEXAGM <dbl>, DMQMILIZ <dbl>, DMQADFC <dbl>,\n#   DMDBORN4 <dbl>, DMDCITZN <dbl>, DMDYRSUS <dbl>, DMDEDUC3 <dbl>,\n#   DMDEDUC2 <dbl>, DMDMARTL <dbl>, RIDEXPRG <dbl>, SIALANG <dbl>,\n#   SIAPROXY <dbl>, SIAINTRP <dbl>, FIALANG <dbl>, FIAPROXY <dbl>,\n#   FIAINTRP <dbl>, MIALANG <dbl>, MIAPROXY <dbl>, MIAINTRP <dbl>,\n#   AIALANGA <dbl>, DMDHHSIZ <dbl>, DMDFMSIZ <dbl>, DMDHHSZA <dbl>,\n#   DMDHHSZB <dbl>, DMDHHSZE <dbl>, DMDHRGND <dbl>, DMDHRAGZ <dbl>, ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\nðŸ‘†**Here's what we did above:**\n\n* We used `haven`'s `read_xpt()` function to import a SAS Transport File directly from the NHANES website. That data was imported as a data frame and we assigned that data frame to the R object called `nhanes_demo`.\n\n* Because this is a large data frame (9,254 observations and 46 variables), we used the `head()` function to print only the first 6 rows of the data to the screen. \n\n## Importing Stata data sets\n\nFinally, we will import a Stata data set (.dta) to round out our discussion of importing data from other statistical analysis software packages. There isn't much of anything new here -- you could probably have even guessed how to do this without us showing you.\n\n[You may click here to download this file to your computer.](https://github.com/brad-cannell/r4epi/blob/master/data/height_and_weight.dta)\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstata <- read_stata(\"height_and_weight.dta\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstata\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 x 4\n  ID    sex    ht_in wgt_lbs\n  <chr> <chr>  <dbl>   <dbl>\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n```\n\n\n:::\n:::\n\n\n\n\n\n\nðŸ‘†**Here's what we did above:**\n\n* We used `haven`'s `read_stata()` function to import a Stata data set. That data was imported as a data frame and we assigned that data frame to the R object called `stata`.\n\nYou now know how to write code that will allow you to import data stored in all of the file formats that we will use in this book, and the vast majority of formats that you are likely to encounter in your real-world projects. In the next section, We will introduce you to a tool in RStudio that makes importing data even easier. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}