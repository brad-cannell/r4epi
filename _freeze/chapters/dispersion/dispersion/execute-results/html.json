{
  "hash": "4e68314678d00d3de6c595cb2e295364",
  "result": {
    "engine": "knitr",
    "markdown": "# Measures of Dispersion\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the chapter on [measures of central tendency](../central_tendency/central_tendency.qmd), we found the minimum value, mean value, median value, mode value, and maximum value of the weight variable in our hypothetical sample of students. We'll go ahead and start this lesson by rerunning that analysis below, but this time we will analyze heights instead of weights.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the dplyr package. We will need several of dplyr's functions in the \n# code below.\nlibrary(dplyr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate some data\nheight_and_weight_20 <- tribble(\n  ~id,   ~sex,     ~ht_in, ~wt_lbs,\n  \"001\", \"Male\",   71,     190,\n  \"002\", \"Male\",   69,     177,\n  \"003\", \"Female\", 64,     130,\n  \"004\", \"Female\", 65,     153,\n  \"005\", NA,       73,     173,\n  \"006\", \"Male\",   69,     182,\n  \"007\", \"Female\", 68,     186,\n  \"008\", NA,       73,     185,\n  \"009\", \"Female\", 71,     157,\n  \"010\", \"Male\",   66,     155,\n  \"011\", \"Male\",   71,     213,\n  \"012\", \"Female\", 69,     151,\n  \"013\", \"Female\", 66,     147,\n  \"014\", \"Female\", 68,     196,\n  \"015\", \"Male\",   75,     212,\n  \"016\", \"Female\", 69,     19000,\n  \"017\", \"Female\", 66,     194,\n  \"018\", \"Female\", 65,     176,\n  \"019\", \"Female\", 65,     176,\n  \"020\", \"Female\", 65,     102\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Recreate our mode function\nmode_val <- function(x) {\n  value_counts <- table(x)\n  result <- names(value_counts)[value_counts == max(value_counts)]\n  if (length(value_counts) == length(result)) {\n    result <- NA\n  }\n  result\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nheight_and_weight_20 %>% \n  summarise(\n    min_height    = min(ht_in),\n    mean_height   = mean(ht_in),\n    median_height = median(ht_in),\n    mode_height   = mode_val(ht_in) %>% paste(collapse = \" , \"),\n    max_height    = max(ht_in)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 √ó 5\n  min_height mean_height median_height mode_height max_height\n       <dbl>       <dbl>         <dbl> <chr>            <dbl>\n1         64        68.4          68.5 65 , 69             75\n```\n\n\n:::\n:::\n\n\n\n\n\n\n::: {.callout-note}\nTo get both mode height values to display in the output above we used the `paste()` function with the collapse argument set to \" , \" (notice the spaces). This forces R to display our mode values as a character string. The downside is that the ‚Äúmode_height‚Äù variable no longer has any numeric value to R -- it's simply a character string. However, this isn't a problem for us. We won't be using the mode in this lesson -- and it is rarely used in practice.\n:::\n\nKeep in mind that our interest is in describing the ‚Äútypical‚Äù or ‚Äúaverage‚Äù person in our sample. The result of our analysis above tells us that the average person who answered the height question in our hypothetical class was: 68.4 inches. This information gets us reasonably close to understanding the typical height of the students in our hypothetical class. But remember, our average person does not necessarily have the same height as any __actual person__ in our class. So a natural extension of our original question is: ‚Äúhow much like the average person, are the other people in class.‚Äù\n\nFor example, is everyone in class 68.4 inches? \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example with people with the same height](dispersion_01_people.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nOr are there differences in everyone‚Äôs height, with the average person‚Äôs height always having a value in the middle of everyone else‚Äôs?\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example with people of different heights](dispersion_02_people.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nThe measures used to answer this question are called measures of dispersion, which we can say is the amount of difference between people in the class, or more generally, the amount of variability in the data.\n\nThree common measures of dispersion used are the:\n\n* **Range**   \n* **Variance**   \n* **Standard Deviation**  \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Measures of dispersion chart](dispersion_03_overview.png){width=1080}\n:::\n:::\n\n\n\n\n\n\n**Range**\n\nThe [range](../appendices/glossary.qmd#glossary-console) is simply the difference between the maximum and minimum value in the data. \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nheight_and_weight_20 %>% \n  summarise(\n    min_height  = min(ht_in),\n    mean_height = mean(ht_in),\n    max_height  = max(ht_in),\n    range       = max_height - min_height\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 √ó 4\n  min_height mean_height max_height range\n       <dbl>       <dbl>      <dbl> <dbl>\n1         64        68.4         75    11\n```\n\n\n:::\n:::\n\n\n\n\n\n\nIn this case, the range is 11. The range can be useful because it tells us how much difference there is between the tallest person in our class and the shortest person in our class -- 11 inches. However, it doesn‚Äôt tell us how close to 68.4 inches ‚Äúmost‚Äù people in the class are.\n\nIn other words, are most people in the class out at the edges of the range of values in the data? \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example with people's heights on the edges of the range](dispersion_04_edges.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nOr are people ‚Äúevenly distributed‚Äù across the range of heights for the class? \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example with people's heights evenly distributed across the range](dispersion_05_even.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nOr something else entirely?\n\n**Variance**\n\nThe [variance](../appendices/glossary.qmd#glossary-variance) is a measure of dispersion that is slightly more complicated to calculate, although not much, but gives us a number we can use to quantify the dispersion of heights around the mean. To do this, let‚Äôs work through a simple example that only includes six observations: 3 people who are 58 inches tall and 3 people who are 78 inches tall. In this sample of six people from our population the average height is 68 inches.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example with people's heights on the edges of the range](dispersion_04_edges.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nNext, let‚Äôs draw an imaginary line straight up from the mean.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Drawing an maginary line at the mean height](dispersion_06_variance.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nThen, let‚Äôs measure the difference, or distance, between each person‚Äôs height and the mean height.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Calculating the differences between individual heights and the mean height](dispersion_07_variance.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nThen we square the differences. \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Squaring the differences between individual heights and the mean height](dispersion_08_variance.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nThen we add up all the squared differences.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Adding the squared differences between individual heights and the mean height](dispersion_09_variance.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nAnd finally, we divide by n, the number of non-missing observations, minus 1. In this case n equals six, so n-1 equals five.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Dividing the sum of the squared differences between individual heights and the mean height by n](dispersion_10_variance.png){width=1080}\n:::\n:::\n\n\n\n\n\n\n::: {.callout-note}\nThe sample variance is often written as $s^2$.\n:::\n\n::: {.callout-note}\nIf the 6 observations here represented our entire population of interest, then we could simply divide by n instead of n-1.\n:::\n\nGetting R to do this math for us is really straightforward. We simply use base R's `var()` function.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar(c(rep(58, 3), rep(78, 3)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 120\n```\n\n\n:::\n:::\n\n\n\n\n\n\nüëÜ **Here's what we did above:**\n\n* We created a numeric vector of heights using the `c()` function. \n\n* Instead of typing `c(58, 58, 58, 78, 78, 78)` we used the `rep()` function. `rep(58, 3)` is equivalent to typing `c(58, 58, 58)` and `rep(78, 3)` is equivalent to typing `c(78, 78, 78)`.\n\n* We passed this numeric vector to the `var()` function and R returned the variance -- 120\n\nSo, 600 divided by 5 equals 120. Therefore, the sample variance in this case is 120. However, because the variance is expressed in squared units, instead of the original units, it isn‚Äôt necessarily intuitive to interpret.\n\n**Standard deviation**\n\nIf we take the square root of the variance, we get the [standard deviation](../appendices/glossary.qmd#glossary-standard-deviation). \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Obtaining the standard deviation by taking the square root of the variance](dispersion_11_sd.png){width=1080}\n:::\n:::\n\n\n\n\n\n\n::: {.callout-note}\nThe sample standard deviation is often written as $s$.\n:::\n\nThe standard deviation is 10.95 inches, which is much easier to interpret, and compare with other samples. Now that we know the sample standard deviation, we can use it to describe a value‚Äôs distance from the mean. Additionally, when our data is approximately normally distributed, then the percentage of values within each standard deviation from the mean follow the rules displayed in this table:\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![68‚Äì95‚Äì99.7 rule for approximately normal data](dispersion_12_sd.png){width=1080}\n:::\n:::\n\n\n\n\n\n\nThat is, about 68% of all the observations fall within one standard deviation of the mean (that is, 10.95 inches). About 95% of all observations are within 2 standard deviations of the mean (that is, 10.95 * 2 = 21.9 inches), and about 99.9% of all observations are within 3 standard deviations of the mean (that is, 10.95 * 3 = 32.85 inches).\n\nDon't forget that these percentage rules apply to values __around__ the mean. In other words, half the values will be greater than the mean and half the values will be lower than the mean. You will often see this graphically illustrated with a \"normal curve\" or \"bell curve.\"\n\n<!-- Helpful site: http://t-redactyl.io/blog/2016/03/creating-plots-in-r-using-ggplot2-part-9-function-plots.html -->\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in geom_segment(aes(x = 68, y = 0, xend = 68, yend = peak), color = \"red\", : All aesthetics have length 1, but the data has 2 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](dispersion_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nUnfortunately, the current data is nowhere near normally distributed and does not make for a good example of this rule.\n\n## Comparing distributions\n\nNow that you understand what the different measures of distribution are and how they are calculated, let's further develop your \"feel\" for interpreting them. We can do this by comparing different simulated distributions.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_data <- tibble(\n  all_68     = rep(68, 20),\n  half_58_78 = c(rep(58, 10), rep(78, 10)),\n  even_58_78 = seq(from = 58, to = 78, length.out = 20),\n  half_48_88 = c(rep(48, 10), rep(88, 10)),\n  even_48_88 = seq(from = 48, to = 88, length.out = 20)\n)\nsim_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 √ó 5\n   all_68 half_58_78 even_58_78 half_48_88 even_48_88\n    <dbl>      <dbl>      <dbl>      <dbl>      <dbl>\n 1     68         58       58           48       48  \n 2     68         58       59.1         48       50.1\n 3     68         58       60.1         48       52.2\n 4     68         58       61.2         48       54.3\n 5     68         58       62.2         48       56.4\n 6     68         58       63.3         48       58.5\n 7     68         58       64.3         48       60.6\n 8     68         58       65.4         48       62.7\n 9     68         58       66.4         48       64.8\n10     68         58       67.5         48       66.9\n11     68         78       68.5         88       69.1\n12     68         78       69.6         88       71.2\n13     68         78       70.6         88       73.3\n14     68         78       71.7         88       75.4\n15     68         78       72.7         88       77.5\n16     68         78       73.8         88       79.6\n17     68         78       74.8         88       81.7\n18     68         78       75.9         88       83.8\n19     68         78       76.9         88       85.9\n20     68         78       78           88       88  \n```\n\n\n:::\n:::\n\n\n\n\n\n\nüëÜ **Here's what we did above:**\n\n* We created a data frame with 5 simulated distributions:\n\n  - all_68 has a value of 68 repeated 20 times\n  \n  - half_58_78 is made up of the values 58 and 78, each repeated 10 times (similar to our example above)\n  \n  - even_58_78 is 20 evenly distributed numbers between 58 and 78\n  \n  - half_48_88 is made up of the values 48 and 88, each repeated 10 times\n  \n  - even_48_88 is 20 evenly distributed numbers between 48 and 88\n\nWe will use this simulated data to quickly demonstrate a couple of these concepts. Let‚Äôs use R to calculate and compare the mean, variance, and standard deviation of each variable.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  Column   = names(sim_data),\n  Mean     = purrr::map_dbl(sim_data, mean),\n  Variance = purrr::map_dbl(sim_data, var),\n  SD       = purrr::map_dbl(sim_data, sd)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 4\n  Column      Mean Variance    SD\n  <chr>      <dbl>    <dbl> <dbl>\n1 all_68        68      0    0   \n2 half_58_78    68    105.  10.3 \n3 even_58_78    68     38.8  6.23\n4 half_48_88    68    421.  20.5 \n5 even_48_88    68    155.  12.5 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nüëÜ **Here's what we did above:**\n\n* We created a data frame to hold some summary statistics about each column in the \"sim_data\" data frame.\n\n* We used the `map_dbl()` function from the `purrr` package to iterate over each column in the data. Don't worry too much about this right now. We will talk more about iteration and the `purrr` package later in the book. \n\nSo, for all the columns the mean is 68 inches. And that makes sense, right? We set the middle value and/or most commonly occurring value to be 68 inches for each of these variables. However, the variance and standard deviation are quite different.\n\nFor the column \"all_68\" the variance and standard deviation are both zero. If you think about it, this should make perfect sense: all the values are 68 ‚Äì they don‚Äôt vary ‚Äì and each observations distance from the mean (68) is zero.\n\nWhen comparing the rest of the columns notice that all of them have a non-zero variance. This is because not all people have the same value in that column ‚Äì they vary. Additionally, we can see very clearly that variance (and standard deviation) are affected by at least two things:\n\n1. First is the distribution of values across the range of possible values. For example, half_58_78 and half_48_88 have a larger variance than even_58_78 and even_48_88 because all the values are clustered at the min and max - far away from the mean.\n\n2. The second property of the data that is clearly influencing variance is the width of the range of values included in the distribution. For example, even_48_88 has a larger variance and standard deviation than even_58_78, even though both are evenly distributed across the range of possible values. The reason is because the range of possible values is larger, and therefore the range of distances from the mean is larger too.\n\nIn summary, although the variance and standard deviation don‚Äôt always have a really intuitive meaning all by themselves, we can get some useful information by __comparing__ them. Generally speaking, the variance is larger when values are clustered at very low or very high values away from the mean, or when values are spread across a wider range.\n\n",
    "supporting": [
      "dispersion_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}